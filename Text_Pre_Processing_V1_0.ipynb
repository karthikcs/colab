{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Pre-Processing V1.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikcs/colab/blob/master/Text_Pre_Processing_V1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxoaL1rJz8HV",
        "colab_type": "text"
      },
      "source": [
        "## Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxTBXyEEdSeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from gensim.models import Word2Vec, KeyedVectors\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuMPCXfNYiiC",
        "colab_type": "text"
      },
      "source": [
        "### Configuration from the user\n",
        "In section, user can specify some of the configuration needed for the tool to run. Example: Input file url, key column to consider, additional stop words etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH6uGJ7kY6wQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Configuration\n",
        "input_file = r'https://storage.googleapis.com/karthik101/Kaplan%20Tickets.csv'\n",
        "description_field = 'Description:'\n",
        "more_stopwords = ['hi', 'hello', 'an', 'please', 'pls', 'dear', 'dears', 'from', 'll', 'bo', 'inc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yM2F8SRQKxc",
        "colab_type": "text"
      },
      "source": [
        "### Input  Data\n",
        "The data which we are trying to process is a ticket history from past one year. It contains more than 20,000 ticket information. The size of the file is almost 50MB. Github supports not more than 25MB, and hence using the google storage from GCP. (Account : karthikcs101)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJHIMwHCdt9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(input_file, encoding = \"ISO-8859-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMVFI_c0Qu_4",
        "colab_type": "text"
      },
      "source": [
        "### Data Cleaning\n",
        "Before we start processing the data, we need to perform following pre-processing\n",
        "\n",
        "We have 2 fields which might affect the topic modelling, Short Description and Long Description. Sometimes one might be important and other time other one. So. we are planning to concatenate both fields before doing anything\n",
        "\n",
        "1.   **Gensim simple_preprocess** - Convert a document into a list of tokens. This lowercases, tokenizes and converts to deaccents\n",
        "2.   **Removing Stopwords** - Removes the stopwords from Spacy. It also removes additional user specified Stopwords\n",
        "3. **Lemmatize** - Using Spacy, converts all the words to Lemmatized words. Example: *message*, *messages*, *messaging* - all gets converted to root word - *message*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QItgXMGtUeMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['key_text'] = df[description_field]\n",
        "data = df.key_text.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYTnOgQSThQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "stop_words = nlp.Defaults.stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK94MxLNWBf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_underscore(sentences):\n",
        "  for sentence in sentences:\n",
        "    yield(sentence.replace('_', ' '))\n",
        "\n",
        "def simple_processing(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(simple_preprocess(str(sentence), deacc=True))  \n",
        "        \n",
        "def remove_stopwords(texts):\n",
        "  return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]        \n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUZqS_YpFzzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = list(replace_underscore(data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt87VKJqGF22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f723df85-d737-4ac9-8d14-6e37d4aa1746"
      },
      "source": [
        "data1[0:10]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FAABoost INC4649505 Testing after migration',\n",
              " 'Genesys Items 02/25-02/28',\n",
              " 'WELD INC4649511 Testing after migration',\n",
              " 'Sharepoint INC4645781 Add Chief Experience Officer to SP&A form',\n",
              " 'FAABoost INC4646535 FAA move in DEV',\n",
              " 'Necesito que me ayudes a crear unas cuentas en test porfavor',\n",
              " 'WELD INC4644786 First Data Password Reset',\n",
              " 'ECMS INC4645219 Create a report of all assets in Production',\n",
              " 'BT INC4645196 Biztalk Health Check Report 02/18/2019 - 02/22/2019',\n",
              " '1098T INC4645659 Write Off Issue']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leryhadJWz-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Step 1: Data simple processing\n",
        "data_words = list(simple_processing(data1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCqRxfrlEHlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "ab3cfd1e-e798-4802-db67-8a06d440cd35"
      },
      "source": [
        "data_words[0:10]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['faaboost', 'inc', 'testing', 'after', 'migration'],\n",
              " ['genesys', 'items'],\n",
              " ['weld', 'inc', 'testing', 'after', 'migration'],\n",
              " ['sharepoint',\n",
              "  'inc',\n",
              "  'add',\n",
              "  'chief',\n",
              "  'experience',\n",
              "  'officer',\n",
              "  'to',\n",
              "  'sp',\n",
              "  'form'],\n",
              " ['faaboost', 'inc', 'faa', 'move', 'in', 'dev'],\n",
              " ['necesito',\n",
              "  'que',\n",
              "  'me',\n",
              "  'ayudes',\n",
              "  'crear',\n",
              "  'unas',\n",
              "  'cuentas',\n",
              "  'en',\n",
              "  'test',\n",
              "  'porfavor'],\n",
              " ['weld', 'inc', 'first', 'data', 'password', 'reset'],\n",
              " ['ecms',\n",
              "  'inc',\n",
              "  'create',\n",
              "  'report',\n",
              "  'of',\n",
              "  'all',\n",
              "  'assets',\n",
              "  'in',\n",
              "  'production'],\n",
              " ['bt', 'inc', 'biztalk', 'health', 'check', 'report'],\n",
              " ['inc', 'write', 'off', 'issue']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QGW8qetXktI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Removing Stopwords \n",
        "# Skipping for now \n",
        "stop_words = nlp.Defaults.stop_words\n",
        "stp_list = list(stop_words)\n",
        "stp_list.extend(more_stopwords)\n",
        "stop_words = set(stp_list)\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "# data_words_nostops[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKZbHb4tXl86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Step 3: Lemmatize the data words\n",
        "## Skipping for now \n",
        "# data_lemmatized = lemmatization(data_words_nostops)\n",
        "# data_lemmatized[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6CCS21SeRZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9e5fa54a-a1e5-49bb-f3bc-ac44fb224f56"
      },
      "source": [
        "tokanized_sentenaces = data_words_nostops\n",
        "tokanized_sentenaces[:10]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['faaboost', 'testing', 'migration'],\n",
              " ['genesys', 'items'],\n",
              " ['weld', 'testing', 'migration'],\n",
              " ['sharepoint', 'add', 'chief', 'experience', 'officer', 'sp', 'form'],\n",
              " ['faaboost', 'faa', 'dev'],\n",
              " ['necesito',\n",
              "  'que',\n",
              "  'ayudes',\n",
              "  'crear',\n",
              "  'unas',\n",
              "  'cuentas',\n",
              "  'en',\n",
              "  'test',\n",
              "  'porfavor'],\n",
              " ['weld', 'data', 'password', 'reset'],\n",
              " ['ecms', 'create', 'report', 'assets', 'production'],\n",
              " ['bt', 'biztalk', 'health', 'check', 'report'],\n",
              " ['write', 'issue']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIZaIzguG9Fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_wordlist_to_text(wordlist):\n",
        "  out_list = []\n",
        "  for item in wordlist:\n",
        "    str1 = ' '.join(item)\n",
        "    out_list.append(str1)\n",
        "  return out_list  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huxcwUQxH1Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_text = convert_wordlist_to_text(tokanized_sentenaces)\n",
        "df['clean_text'] = clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsAEcw1YtR1p",
        "colab_type": "code",
        "outputId": "dd94ef7c-52c3-4a85-eb52-6ad2eec082d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "df.to_csv('clean_text.csv')\n",
        "!curl -X POST --data-binary @'clean_text.csv' -H \"Content-Type: text/csv\" \"https://www.googleapis.com/upload/storage/v1/b/karthik101/o?uploadType=media&name=clean_text.csv\""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            " \"kind\": \"storage#object\",\n",
            " \"id\": \"karthik101/clean_text.csv/1561994722196827\",\n",
            " \"selfLink\": \"https://www.googleapis.com/storage/v1/b/karthik101/o/clean_text.csv\",\n",
            " \"name\": \"clean_text.csv\",\n",
            " \"bucket\": \"karthik101\",\n",
            " \"generation\": \"1561994722196827\",\n",
            " \"metageneration\": \"1\",\n",
            " \"contentType\": \"text/csv\",\n",
            " \"timeCreated\": \"2019-07-01T15:25:22.196Z\",\n",
            " \"updated\": \"2019-07-01T15:25:22.196Z\",\n",
            " \"storageClass\": \"MULTI_REGIONAL\",\n",
            " \"timeStorageClassUpdated\": \"2019-07-01T15:25:22.196Z\",\n",
            " \"size\": \"331459\",\n",
            " \"md5Hash\": \"bEIkcZbswH9qIvVpzobiCw==\",\n",
            " \"mediaLink\": \"https://www.googleapis.com/download/storage/v1/b/karthik101/o/clean_text.csv?generation=1561994722196827&alt=media\",\n",
            " \"crc32c\": \"TPNXxQ==\",\n",
            " \"etag\": \"CNv6uuSDlOMCEAE=\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO_-HcKKdirN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}